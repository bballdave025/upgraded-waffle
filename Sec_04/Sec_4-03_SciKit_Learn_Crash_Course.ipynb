{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SciKit Learn Preprocessing Overview</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete reproducability, if it can be done in under 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Only here for reproducibility\")\n",
    "np.random.seed(101)\n",
    "a = np.random.randint(1, 1000, (1, 10)) \n",
    "mat = np.random.randint(0, 1000, (10, 10))\n",
    "print(\"Only here for reproducibility (specifically or the random integer array)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(data) + \"\\n\\n\" + str(type(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &lt; SKIP &gt;\n",
    "\n",
    "No more time on this part. `-- v --`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  First, scaling between 0 and 1 based on the:\n",
    "# #+ min (3) ; and the max (94). My guess (DWB, 2023-11-13)\n",
    "# #+ is that it's fine tuning on something like\n",
    "# #+   output(in) = (in - min) / (max - min) = (in - 3) / (94 - 3)\n",
    "# #+ There are problems with the 92 -> 1. and the 6 -> 0., which\n",
    "# #+ is where the fine tuning comes in\n",
    "# scaler_model = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, here we go from the docs.\n",
    "\n",
    "\n",
    "> `The transformation is given by::                                  ` <br/>\n",
    "> `                                                                  ` <br/>\n",
    "> `    X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) ` <br/>\n",
    "> `    X_scaled = X_std * (max - min) + min                          ` <br/>\n",
    "> `                                                                  ` <br/>\n",
    "> `where min, max = feature_range.                                   ` <br/>\n",
    "> `                                                                  ` <br/>\n",
    "> `This transformation is often used as an alternative to zero mean, ` <br/>\n",
    "> `unit variance scaling.                                            `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(scaler_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scikitlearn_transform(in_val, min_val=3, max_val=94):\n",
    "#     '''\n",
    "#     Simple (not vectorized) test of the normalization transformation\n",
    "#     performed by sklearn.preprocessing.data.MinMaxScaler.fit\n",
    "#     When I say not vectorized, I mean it just takes one input number\n",
    "#     to be transformed, along with the max and min, and only gives\n",
    "#     one output. It is specialized for the data from the lecture.\n",
    "    \n",
    "#     DWB, 2023-11-13\n",
    "#     '''\n",
    "    \n",
    "#     do_debug = False\n",
    "    \n",
    "#     x_in_val = float(in_val)\n",
    "    \n",
    "#     x_std_skl = standard_transform(x_in_val, min_val, max_val)\n",
    "    \n",
    "#     if do_debug:\n",
    "#         print(\"x_std_skl:\" + str(x_std_skl))\n",
    "#     ##endof:  if do_debug\n",
    "    \n",
    "#     theory_data_min = 0\n",
    "#     theory_data_max = 100\n",
    "    \n",
    "#     theory_feat_max = 1.0\n",
    "#     theory_feat_min = 0.0\n",
    "    \n",
    "    \n",
    "#     # #This one would just give you back what you put in\n",
    "#     # x_scaled_skl = x_std_skl * (max_val - min_val) + min_val\n",
    "#     #                # exactly the same output as input\n",
    "    \n",
    "#     # # I'm pretty sure these two are wrong, too, but let's investigate\n",
    "#     # x_scaled_skl = \\\n",
    "#     #     x_std_skl * (theory_feat_max - theory_feat_min) + theory_feat_min\n",
    "#     #     # exactly the same output as input\n",
    "#     # x_scaled_skl = \\\n",
    "#     #     x_std_skl * (theory_data_max - theory_data_min) + theory_data_min\n",
    "#     #     # weird messed up\n",
    "    \n",
    "#     min_val_to_use, max_val_to_use = \\\n",
    "#         data_min_max_4_normalize(\n",
    "#                      x_in_val,\n",
    "#                      min_val, max_val,\n",
    "#                      theory_data_min, theory_data_max,\n",
    "#                      theory_feat_min, theory_feat_max)\n",
    "    \n",
    "#     if do_debug:\n",
    "#         print(\"min_val_to_use: \" + str(min_val_to_use))\n",
    "#         print(\"max_val_to_use: \" + str(max_val_to_use))\n",
    "#     ##endof:  if do_debug\n",
    "    \n",
    "#     x_scaled_skl = \\\n",
    "#         x_std_skl * (max_val_to_use - min_val_to_use) + min_val_to_use\n",
    "    \n",
    "#     if do_debug:\n",
    "#         print(\"x_scaled_skl:\" + str(x_scaled_skl))\n",
    "#     ##endof:  if do_debug\n",
    "    \n",
    "#     return x_scaled_skl\n",
    "\n",
    "# ##endof:  scikitlearn_transform(in_val, max_val = 94, min_val = 3)\n",
    "\n",
    "# def standard_transform(in_val_std, min_value, max_value):\n",
    "#     '''\n",
    "#     The standard way of normalizing\n",
    "#     I think this is the \"zero mean, unit variance scaling\"\n",
    "#     '''\n",
    "    \n",
    "#     in_val = in_val_std\n",
    "#     min_val = min_value\n",
    "#     max_val = max_value\n",
    "    \n",
    "#     return float( (in_val - min_val) / (max_val - min_val) )\n",
    "    \n",
    "# ##endof:  standard_transform(in_val, max_val, min_val)\n",
    "\n",
    "# def data_min_max_4_normalize(\n",
    "#                      in_val_data, \n",
    "#                      min_val_data=3., max_val_data=94.,\n",
    "#                      min_theoretical_data=0.,\n",
    "#                      max_theoretical_data=100.,\n",
    "#                      min_theoretical_normed_feature=0.,\n",
    "#                      max_theoretical_normed_feature=1.):\n",
    "#     '''\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     # y = m*x + b\n",
    "#     conv_m_for_data2normed = ((max_theoretical_normed_feature - min_theoretical_normed_feature) / ( max_theoretical_data - min_theoretical_data ))  \n",
    "#      # rise / run\n",
    "    \n",
    "#     # b = y_given - m*x_given, (0, 0) is trivial, but right, let's do (100, 1)\n",
    "#     conv_b_for_data2normed = \\\n",
    "#       max_theoretical_normed_feature - (conv_m_for_data2normed * max_theoretical_data)\n",
    "    \n",
    "#     min_val_ret = conv_m_for_data2normed * min_val_data + conv_b_for_data2normed\n",
    "    \n",
    "#     max_val_ret = conv_m_for_data2normed * max_val_data + conv_b_for_data2normed\n",
    "    \n",
    "#     return min_val_ret, max_val_ret\n",
    "    \n",
    "# ##endof:  data_min_max_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remember the data\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t00 = scikitlearn_transform(92)\n",
    "# print(t00)\n",
    "# t01 = scikitlearn_transform(11)\n",
    "# print(t01)\n",
    "# t10 = scikitlearn_transform(10)\n",
    "# print(t10)\n",
    "# t11 = scikitlearn_transform(94)\n",
    "# print(t11)\n",
    "# t20 = scikitlearn_transform(35)\n",
    "# print(t20)\n",
    "# t21 = scikitlearn_transform(28)\n",
    "# print(t21)\n",
    "# t30 = scikitlearn_transform(3)\n",
    "# print(t30)\n",
    "\n",
    "# lets_see = [[t00, t01],[t10, t11],[t20, t21], [t30, \"...\"]]\n",
    "\n",
    "# import pprint\n",
    "\n",
    "# pprint.pprint(lets_see)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of the part for which there's no more time. `-- ^ --`\n",
    "\n",
    "## &lt; / SKIP &gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  First, scaling between 0 and 1 based on the:\n",
    "#+ min (3) ; and the max (94). This will include\n",
    "#+ three lines of code:\n",
    "#\n",
    "# % scaler_model = MinMaxScaler()\n",
    "# % scaler_model.fit(data)\n",
    "# % scaler_model\n",
    "\n",
    "scaler_model = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(scaler_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_model.fit(data) # A warning will come up, because it converts ints to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = scaler_model.transform(data)\n",
    "\n",
    "print(str(normalized_data) + \"\\n\\n\" + str(type(normalized_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, you fit to your training data and use the resulting fit to transform both training and test data. (No fitting on the test data!) However, for possible learning exercises or quick tests, there is the following function that both fits and transforms the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Not usually good practice.\n",
    "#+ Still, so you can see it gives the same thing.\n",
    "one_step_result = scaler_model.fit_transform(data)\n",
    "\n",
    "print(str(one_step_result) + \"\\n\\n\" + str(type(one_step_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That can be compared to the original.\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That can be compared to the original.\n",
    "\n",
    "print(str(data) + \"\\n\\n\" + str(type(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_And now, some Pandas stuff!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
