{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SciKit Learn Preprocessing Overview</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete reproducability, if it can be done in under 10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Only here for reproducibility\")\n",
    "#np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Only here for reproducibility\")\n",
    "np.random.seed(101)\n",
    "#np.random.randint(1, 1000, (1, 10))\n",
    "np.random.randint(0, 1000, (11, 10))\n",
    "data = np.random.randint(0, 100, (10, 2))\n",
    "print(\"Only here for reproducibility (specifically or the random integer array)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(data) + \"\\n\\n\" + str(type(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &lt; SKIP &gt;\n",
    "\n",
    "No more time on this part. `-- v --`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  First, scaling between 0 and 1 based on the:\n",
    "# #+ min (3) ; and the max (94). My guess (DWB, 2023-11-13)\n",
    "# #+ is that it's fine tuning on something like\n",
    "# #+   output(in) = (in - min) / (max - min) = (in - 3) / (94 - 3)\n",
    "# #+ There are problems with the 92 -> 1. and the 6 -> 0., which\n",
    "# #+ is where the fine tuning comes in\n",
    "# scaler_model = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, here we go from the docs.\n",
    "\n",
    "\n",
    "> `The transformation is given by::                                  ` <br/>\n",
    "> `                                                                  ` <br/>\n",
    "> `    X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) ` <br/>\n",
    "> `    X_scaled = X_std * (max - min) + min                          ` <br/>\n",
    "> `                                                                  ` <br/>\n",
    "> `where min, max = feature_range.                                   ` <br/>\n",
    "> `                                                                  ` <br/>\n",
    "> `This transformation is often used as an alternative to zero mean, ` <br/>\n",
    "> `unit variance scaling.                                            `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(scaler_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scikitlearn_transform(in_val, min_val=3, max_val=94):\n",
    "#     '''\n",
    "#     Simple (not vectorized) test of the normalization transformation\n",
    "#     performed by sklearn.preprocessing.data.MinMaxScaler.fit\n",
    "#     When I say not vectorized, I mean it just takes one input number\n",
    "#     to be transformed, along with the max and min, and only gives\n",
    "#     one output. It is specialized for the data from the lecture.\n",
    "    \n",
    "#     DWB, 2023-11-13\n",
    "#     '''\n",
    "    \n",
    "#     do_debug = False\n",
    "    \n",
    "#     x_in_val = float(in_val)\n",
    "    \n",
    "#     x_std_skl = standard_transform(x_in_val, min_val, max_val)\n",
    "    \n",
    "#     if do_debug:\n",
    "#         print(\"x_std_skl:\" + str(x_std_skl))\n",
    "#     ##endof:  if do_debug\n",
    "    \n",
    "#     theory_data_min = 0\n",
    "#     theory_data_max = 100\n",
    "    \n",
    "#     theory_feat_max = 1.0\n",
    "#     theory_feat_min = 0.0\n",
    "    \n",
    "    \n",
    "#     # #This one would just give you back what you put in\n",
    "#     # x_scaled_skl = x_std_skl * (max_val - min_val) + min_val\n",
    "#     #                # exactly the same output as input\n",
    "    \n",
    "#     # # I'm pretty sure these two are wrong, too, but let's investigate\n",
    "#     # x_scaled_skl = \\\n",
    "#     #     x_std_skl * (theory_feat_max - theory_feat_min) + theory_feat_min\n",
    "#     #     # exactly the same output as input\n",
    "#     # x_scaled_skl = \\\n",
    "#     #     x_std_skl * (theory_data_max - theory_data_min) + theory_data_min\n",
    "#     #     # weird messed up\n",
    "    \n",
    "#     min_val_to_use, max_val_to_use = \\\n",
    "#         data_min_max_4_normalize(\n",
    "#                      x_in_val,\n",
    "#                      min_val, max_val,\n",
    "#                      theory_data_min, theory_data_max,\n",
    "#                      theory_feat_min, theory_feat_max)\n",
    "    \n",
    "#     if do_debug:\n",
    "#         print(\"min_val_to_use: \" + str(min_val_to_use))\n",
    "#         print(\"max_val_to_use: \" + str(max_val_to_use))\n",
    "#     ##endof:  if do_debug\n",
    "    \n",
    "#     x_scaled_skl = \\\n",
    "#         x_std_skl * (max_val_to_use - min_val_to_use) + min_val_to_use\n",
    "    \n",
    "#     if do_debug:\n",
    "#         print(\"x_scaled_skl:\" + str(x_scaled_skl))\n",
    "#     ##endof:  if do_debug\n",
    "    \n",
    "#     return x_scaled_skl\n",
    "\n",
    "# ##endof:  scikitlearn_transform(in_val, max_val = 94, min_val = 3)\n",
    "\n",
    "# def standard_transform(in_val_std, min_value, max_value):\n",
    "#     '''\n",
    "#     The standard way of normalizing\n",
    "#     I think this is the \"zero mean, unit variance scaling\"\n",
    "#     '''\n",
    "    \n",
    "#     in_val = in_val_std\n",
    "#     min_val = min_value\n",
    "#     max_val = max_value\n",
    "    \n",
    "#     return float( (in_val - min_val) / (max_val - min_val) )\n",
    "    \n",
    "# ##endof:  standard_transform(in_val, max_val, min_val)\n",
    "\n",
    "# def data_min_max_4_normalize(\n",
    "#                      in_val_data, \n",
    "#                      min_val_data=3., max_val_data=94.,\n",
    "#                      min_theoretical_data=0.,\n",
    "#                      max_theoretical_data=100.,\n",
    "#                      min_theoretical_normed_feature=0.,\n",
    "#                      max_theoretical_normed_feature=1.):\n",
    "#     '''\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     # y = m*x + b\n",
    "#     conv_m_for_data2normed = ((max_theoretical_normed_feature - min_theoretical_normed_feature) / ( max_theoretical_data - min_theoretical_data ))  \n",
    "#      # rise / run\n",
    "    \n",
    "#     # b = y_given - m*x_given, (0, 0) is trivial, but right, let's do (100, 1)\n",
    "#     conv_b_for_data2normed = \\\n",
    "#       max_theoretical_normed_feature - (conv_m_for_data2normed * max_theoretical_data)\n",
    "    \n",
    "#     min_val_ret = conv_m_for_data2normed * min_val_data + conv_b_for_data2normed\n",
    "    \n",
    "#     max_val_ret = conv_m_for_data2normed * max_val_data + conv_b_for_data2normed\n",
    "    \n",
    "#     return min_val_ret, max_val_ret\n",
    "    \n",
    "# ##endof:  data_min_max_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remember the data\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t00 = scikitlearn_transform(92)\n",
    "# print(t00)\n",
    "# t01 = scikitlearn_transform(11)\n",
    "# print(t01)\n",
    "# t10 = scikitlearn_transform(10)\n",
    "# print(t10)\n",
    "# t11 = scikitlearn_transform(94)\n",
    "# print(t11)\n",
    "# t20 = scikitlearn_transform(35)\n",
    "# print(t20)\n",
    "# t21 = scikitlearn_transform(28)\n",
    "# print(t21)\n",
    "# t30 = scikitlearn_transform(3)\n",
    "# print(t30)\n",
    "\n",
    "# lets_see = [[t00, t01],[t10, t11],[t20, t21], [t30, \"...\"]]\n",
    "\n",
    "# import pprint\n",
    "\n",
    "# pprint.pprint(lets_see)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of the part for which there's no more time. `-- ^ --`\n",
    "\n",
    "## &lt; / SKIP &gt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  First, scaling between 0 and 1 based on the:\n",
    "#+ min (3) ; and the max (94). This will include\n",
    "#+ three lines of code:\n",
    "#\n",
    "# % scaler_model = MinMaxScaler()\n",
    "# % scaler_model.fit(data)\n",
    "# % scaler_model.transform(data)\n",
    "\n",
    "scaler_model = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(scaler_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_model.fit(data) # A warning will come up, because it converts ints to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = scaler_model.transform(data)\n",
    "\n",
    "print(str(normalized_data) + \"\\n\\n\" + str(type(normalized_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, you fit to your training data and use the resulting fit to transform both training and test data. (No fitting on the test data!) However, for possible learning exercises or quick tests, there is the following function that both fits and transforms the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Not usually good practice.\n",
    "#+ Still, so you can see it gives the same thing.\n",
    "one_step_result = scaler_model.fit_transform(data)\n",
    "\n",
    "print(str(one_step_result) + \"\\n\\n\" + str(type(one_step_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That can be compared to the original.\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(data) + \"\\n\\n\" + str(type(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_And now, some Pandas stuff!_\n",
    "\n",
    "We'll do the train/test split, here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = np.random.randint(0, 101, (50, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's name the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data=mydata, columns=['f1', 'f2', 'f3', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data on which we'll do the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['f1', 'f2', 'f3']] # This is wrong, and it will throw an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do it right, with the Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[['f1', 'f2', 'f3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in a Jupyter notebook, it's very easy to simply write\n",
    "\n",
    "`train_test_split`\n",
    "\n",
    "into the next cell, then do the <kbd>Shift</kbd> + <kbd>Tab</kbd>\n",
    "a couple times until we find the following text to copy/paste\n",
    "\n",
    "```\n",
    ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.33, random_state=42)\n",
    "...\n",
    "```\n",
    "\n",
    "We can then put it all on one line, so we don't get an error with the ellipses, and change the parameters as we'd like. Let's match Jose's lecture.\n",
    "\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split # Put the cursor after the 'train_test_split', then get the docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_That's not all for now, yet._\n",
    "\n",
    "I'm going the follow the course materials, though I'm not going to go through the trouble of making things repeatable. You'll see my efforts to get it there, but that was enough. (My therapist would be so proud!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Only here for reproducibility\")\n",
    "np.random.seed(101)\n",
    "#np.random.randint(1, 1000, (1, 10))\n",
    "np.random.randint(0, 1000, (11, 10))\n",
    "data = np.random.randint(0, 100, (10, 2))\n",
    "print(\"Only here for reproducibility (specifically or the random integer array)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=np.random.randint(0, 101, (50, 4)),\n",
    "                    columns=['f1', 'f2', 'f3', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[['f1', 'f2', 'f3']] # Alternatively: x = data.drop('label', axis=1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "                        train_test_split(x, y, \n",
    "                                         test_size=0.3,\n",
    "                                         random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_That's all for now, folks!_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
